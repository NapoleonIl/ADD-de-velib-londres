---
title: "ADD"
author: "S&T"
date: "2024-11-15"
output: html_document
---
I.Choix de donnes

II. Description de donnes
Metadata:
"timestamp" - timestamp field for grouping the data
"cnt" - the count of a new bike shares
"t1" - real temperature in C
"t2" - temperature in C "feels like"
"hum" - humidity in percentage
"wind_speed" - wind speed in km/h
"weather_code" - category of the weather
"is_holiday" - boolean field - 1 holiday / 0 non holiday
"is_weekend" - boolean field - 1 if the day is weekend
"season" - category field meteorological seasons: 0-spring ; 1-summer; 2-fall; 3-winter.

"weathe_code" category description:
1 = Clear ; mostly clear but have some values with haze/fog/patches of fog/ fog in vicinity 
2 = scattered clouds / few clouds 
3 = Broken clouds 
4 = Cloudy 
7 = Rain/ light Rain shower/ Light rain 
10 = rain with thunderstorm 
26 = snowfall 
94 = Freezing Fog

We are



III. ANALYSE SUR R

1.import
```{r}
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)

# Load the dataset (adjust the path as needed)
#file_path <- "C:\Users\HSBC\OneDrive\桌面\projet\archive"
bike_data <- london_merged ##read_excel(file_path) ## It's not working

# Inspect the data
head(bike_data)
str(bike_data)
summary(bike_data)

colSums(is.na(bike_data)) # Clean check

```
#Tsf de donne (Rename factors)



```{r}
# Parse timestamp and add additional time-based features
bike_data <- bike_data %>%
  mutate(
    timestamp = as.POSIXct(timestamp),
    year = format(timestamp, "%Y"),
    month = format(timestamp, "%m"),
    day = format(timestamp, "%d"),
    hour = format(timestamp, "%H"),
    season = factor(season, labels = c("Spring", "Summer", "Fall", "Winter")),
    weather_code = factor(weather_code, 
                          levels = c(1, 2, 3, 4, 7, 10, 26, 94),
                          labels = c("Clear", "Few Clouds", "Broken Clouds", 
                                     "Cloudy", "Rain", "Thunderstorm", 
                                     "Snowfall", "Freezing Fog"))
  )
bike_data
                    


```


Analyse qualitative
```{r}
#resume numerique

weather_dist <- bike_data %>%
  count(weather_code)
weather_dist

bike_data %>% filter(weather_code == "Freezing Fog") 

```

# D'apres ce res on a pas frezzing_fog, only 6 weather conditions founded

```{r}
#resume graphique
ggplot(weather_dist, aes(x = weather_code, y = n, fill = weather_code)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribution of Weather Conditions", x = "Weather Code", y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Descriptive statistics for `cnt`
summary(bike_data$cnt)


sd_cnt <- sd(bike_data$cnt)
range_cnt <- range(bike_data$cnt)

sd_cnt
range_cnt



```
```{r}
# Histogram of `cnt`
ggplot(bike_data, aes(x = cnt)) +
  geom_histogram(binwidth = 200, fill = "blue", color = "white", alpha = 0.7) +
  labs(title = "Histogram of Bike Counts", x = "Bike Counts", y = "Frequency") +
  theme_minimal()

# Density plot of `cnt`
ggplot(bike_data, aes(x = cnt)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(title = "Density Plot of Bike Counts", x = "Bike Counts", y = "Density") +
  theme_minimal()

```
#obs: cnt suivis loi Poisson, a verfier


III.3 Un lien entre deux var. quantitatives

1 : Visualisation de la Relation
```{r}
# Scatter plot: t1 (température) vs. cnt (comptes de vélos)
ggplot(bike_data, aes(x = t1, y = cnt)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Relation entre la température réelle et les comptes de vélos",
    x = "Température réelle (°C)",
    y = "Nombre de partages de vélos"
  ) +
  theme_minimal()



```

```{r}
# Calcul du coefficient de corrélation
correlation <- cor(bike_data$t1, bike_data$cnt, use = "complete.obs")

## Affichage du résultat
cat("Coefficient de corrélation (t1 et cnt) :", correlation, "\n")

## Test de corrélation de Pearson
cor_test <- cor.test(bike_data$t1, bike_data$cnt)

## Affichage du résultat
cor_test
```


pas de temperature extreme donc t1 et cnt sont liees et de facon logique de correlation positive (plus il fait beau plus les gens sortent)

III.4
```{r}



# Table de contingence entre `season` et `weather_code`
contingence_table <- table(bike_data$season, bike_data$weather_code)

# Affichage de la table
print(contingence_table)

```
```{r}
# Graphique en barres empilées
ggplot(bike_data, aes(x = season, fill = weather_code)) +
  geom_bar(position = "fill") +
  labs(
    title = "Distribution des codes météo par saison",
    x = "Saison",
    y = "Proportion",
    fill = "Code météo"
  ) +
  theme_minimal()

```
```{r}
# Test du Chi-2 sur la table de contingence
chi2_test <- chisq.test(contingence_table)

# Résultat du test
print(chi2_test)

```

#le warning vient du fait qu il n y a pas assez de valeur pour certain weather code comme thunderstorm et freezing fog


III.5 Un lien entre var. quant et var. qualitative
```{r}
# Résumé de `cnt` par code météo
summary_by_weather <- bike_data %>%
  group_by(weather_code) %>%
  summarise(
    moyenne = mean(cnt),
    mediane = median(cnt),
    ecart_type = sd(cnt),
    minimum = min(cnt),
    maximum = max(cnt)
  )

print(summary_by_weather)

```


```{r}
# Boxplot de `cnt` par `weather_code`
ggplot(bike_data, aes(x = weather_code, y = cnt, fill = weather_code)) +
  geom_boxplot() +
  labs(
    title = "Répartition des comptes de vélos par code météo",
    x = "Code météo",
    y = "Nombre de partages de vélos"
  ) +
  theme_minimal()

```
###analyse correlation 
# Test de Kruskal-Wallis
kruskal_test_weather <- kruskal.test(cnt ~ weather_code, data = bike_data)
print(kruskal_test_weather)

####option2
# Modèle de base (sans weather_code)
glm_poisson_null <- glm(cnt ~ 1, family = poisson(link = "log"), data = bike_data)

# Comparaison des modèles avec un test du rapport de vraisemblance
anova(glm_poisson_null, glm_poisson, test = "Chisq")


III.6

Étape 1 : Ajustement d'un Modèle Linéaire

```{r}
# Ajustement du modèle linéaire
modele_lm <- lm(cnt ~ t2 , data = bike_data)
# Résumé du modèle
summary(modele_lm)

```
```{r}
# Ajustement du modèle linéaire
modele_lm <- lm(cnt ~ t1 +  hum , data = bike_data)
# Résumé du modèle
summary(modele_lm)
```
```{r}
# Ajustement du modèle linéaire
modele_lm <- lm(cnt ~ t1 + hum + wind_speed , data = bike_data)
# Résumé du modèle
summary(modele_lm)
```

```{r}
# Extraction des résidus
residus <- residuals(modele_lm)

# Visualisation des résidus
par(mfrow = c(2, 2))  # Affiche quatre graphiques dans une seule figure
plot(modele_lm)
```


```{r}
# Installer le package nortest si nécessaire
if (!require(nortest)) install.packages("nortest")
library(nortest)

# Test d'Anderson-Darling
ad_test <- ad.test(residus)
print(ad_test)
```

pas de distribution normal







